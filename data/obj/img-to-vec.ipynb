{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\n",
    "from keras.applications import Xception, VGG19, InceptionV3, imagenet_utils\n",
    "import keras.backend as K\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "import glob, os\n",
    "\n",
    "image_sizes = [32, 128]\n",
    "vectorizers = ['Xception']\n",
    "projectors = [UMAP(min_dist=0.0001, n_neighbors=20)]\n",
    "\n",
    "class Projector:\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    self.clf = kwargs.get('clf')\n",
    "    \n",
    "  def fit_transform(self, vecs):\n",
    "    return self.clf.fit_transform(vecs)\n",
    "\n",
    "class Image:\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    self.path = kwargs.get('path')\n",
    "    self.original = load_img(self.path)\n",
    "    self.resized = {s: self.resize(s) for s in image_sizes}\n",
    "    self.vectors = {v: self.vectorize(v) for v in vectorizers}\n",
    "    \n",
    "  def resize(self, n):\n",
    "    '''\n",
    "    Resize self.original into a square image with shape n,n while maintaining proportion\n",
    "    '''\n",
    "    s = self.original.size\n",
    "    size = (n, int(n * s[1]/s[0])) if s[0] > s[1] else (int(n * s[0]/s[1]), n)\n",
    "    return self.original.resize(size)\n",
    "    \n",
    "  def vectorize(self, vectorizer_name):\n",
    "    '''\n",
    "    Given the name of a vectorizer model, return a vector representation of this image\n",
    "    '''\n",
    "    if vectorizer_name == 'Xception':\n",
    "      # VGG16, VGG19, and ResNet take 224×224 images; InceptionV3 and Xception take 299×299 inputs\n",
    "      img = self.original.resize((299,299))\n",
    "      arr = img_to_array(img)\n",
    "      # only Xception requires preprocessing\n",
    "      arr = imagenet_utils.preprocess_input(arr)\n",
    "      # input shape must be n_images, h, w, colors: https://keras.io/preprocessing/image/\n",
    "      arr = np.expand_dims(arr, axis=0)\n",
    "      # extract the ith layer from the model (here, the -1th layer, or final layer)\n",
    "      out = K.function([model.input], [model.layers[-1].output])([arr])\n",
    "      # return a 1000, dim vector\n",
    "      return out[0][0]\n",
    "    else:\n",
    "      raise Exception('Requested model not implemented', model_name)\n",
    "    \n",
    "# process each image, project each\n",
    "images = [Image(path=i) for i in glob.glob('images/*')]\n",
    "for i in vectorizers:\n",
    "  vecs = np.array([k.vectors[i] for k in images])\n",
    "  for j in projectors: \n",
    "    projection = Projector(clf=j).fit_transform(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.993591 ,  0.5255954],\n",
       "       [-4.1110463,  2.2405868],\n",
       "       [-3.432333 ,  1.2341529],\n",
       "       [-4.0282307,  1.5279508],\n",
       "       [-5.1479616,  1.2633549],\n",
       "       [-4.847983 ,  0.6344916]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
